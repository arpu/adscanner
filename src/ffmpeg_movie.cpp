/***************************************************************************
author: Joshua Hampp
date: 2008/01

property of Joshua Hampp
***************************************************************************/

/*
Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:

   1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
   2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
   3. The name of the author may not be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE AUTHOR `Joshua Hampp`AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED 
TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL
THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE 
POSSIBILITY OF SUCH DAMAGE.
*/
#include "ffmpeg_movie.h"
#include "progress.h"
#include <cstdlib>
#include <cstring>

void CFFMPEGLoader::Init() {
	bLock=false;
    av_register_all();
    pFrameRGB=NULL;
	i64DTS=i64PTS=0;
	bOutput=false;
    pFrame=NULL;
    pVCodecCon=NULL;
	pFormatCon=NULL;
	audio_pkt_data=NULL;
	pAudioStream=pVideoStream=NULL;
	audio_pkt_size=0;
	iPKTVideoLength=iPKTAudioLength=0;
	bAudioIsNeeded=bVideoIsNeeded=true;
	for(UINT i=0; i<FFMPEG_PACKET_MAX_SIZE; i++)
		pktLastAudio[i].data=pktLastVideo[i].data=NULL;
	pBuffer=NULL;
	iBufferSize=FFMPEG_PACKET_MAX_SIZE;
	//sws_init(0);
}

bool CFFMPEGLoader::Open(const char *filename, const bool &bOutput) {
	if(0!=av_open_input_file(&pFormatCon,filename,NULL,0,NULL)) return false;

	if(!av_find_stream_info(pFormatCon)<0) return false;

	dump_format(pFormatCon,0,filename,bOutput);

	//search Streams
	videoStream=-1;
	audioStream=-1;

    for(UINT i=0; i<pFormatCon->nb_streams; i++)
        if(pFormatCon->streams[i]->codec->codec_type==CODEC_TYPE_VIDEO)
        {
            videoStream=i;
            break;
        }
    for(UINT i=0; i<pFormatCon->nb_streams; i++)
        if(pFormatCon->streams[i]->codec->codec_type==CODEC_TYPE_AUDIO)
        {
            audioStream=i;
            break;
        }

    if(videoStream==-1)
        return false; // Didn't find a video stream
    if(audioStream==-1)
        return false; // Didn't find a audio stream

    // Get a pointer to the codec context for the video stream
    pVCodecCon = pFormatCon->streams[videoStream]->codec;
	pACodecCon = pFormatCon->streams[audioStream]->codec;

	pVCodecCon->flags=CODEC_FLAG_EMU_EDGE;

	AVCodec *pACodec = avcodec_find_decoder(pACodecCon->codec_id);
	if(!pACodec) return false;
	avcodec_open(pACodecCon, pACodec);

	AVCodec *pVCodec = avcodec_find_decoder(pVCodecCon->codec_id);
	if(pVCodec==NULL) return false;

	if(avcodec_open(pVCodecCon,pVCodec)<0) return false;
	
    //OLD?   Hack to correct wrong frame rates that seem to be generated by some 
    // codecs
    //if(pVCodecCon->frame_rate>1000 && pVCodecCon->frame_rate_base==1)
    //    pVCodecCon->frame_rate_base=1000;
	
	pFrame		 = avcodec_alloc_frame();

	pFrameRGB	 = avcodec_alloc_frame();
/*
	iNumBytes = avpicture_get_size(PIX_FMT_RGB24, pVCodecCon->width,
                            pVCodecCon->height);
	pBuffer = (uint8_t *)av_malloc(iNumBytes*sizeof(uint8_t));

	// Assign appropriate parts of buffer to image planes in pFrameRGB
	// Note that pFrameRGB is an AVFrame, but AVFrame is a superset
	// of AVPicture
	avpicture_fill((AVPicture *)pFrameRGB, pBuffer, PIX_FMT_RGB24,
                pVCodecCon->width, pVCodecCon->height);
*/
	return true;
}

int CFFMPEGLoader::LoadFrame() {
	AVPacket packet;
	int ret=-1;
	while(av_read_frame(pFormatCon, &packet)>=0) {
		ret=1;

		// Is this a packet from the video stream?
		if(bVideoIsNeeded&&packet.stream_index==videoStream&&iPKTVideoLength<iBufferSize) {
			// Decode video frame
			av_dup_packet(&packet);
			pktLastVideo[iPKTVideoLength++]=packet;
			//....
		}
		else if(bAudioIsNeeded&&packet.stream_index==audioStream&&iPKTAudioLength<iBufferSize) {
			av_dup_packet(&packet);
			pktLastAudio[iPKTAudioLength++]=packet;
		}
		else {
			av_free_packet(&packet);
		}

		if(iPKTVideoLength>=iBufferSize||iPKTAudioLength>=iBufferSize) break;
	}

	return ret;
}

AVPacket *CFFMPEGLoader::GetNextPacket() {
	AVPacket packet;
	if(av_read_frame(pFormatCon, &packet)<0)
		return NULL;
	if(packet.stream_index!=videoStream&&packet.stream_index!=audioStream) {
		av_free_packet(&packet);
		return NULL;
	}
	av_dup_packet(&packet);
	return &packet;
}

void CFFMPEGLoader::Delete() {
	for(UINT i=0; i<FFMPEG_PACKET_MAX_SIZE; i++) {
		if(pktLastAudio[i].data)
			av_free_packet(&pktLastAudio[i]);
		if(pktLastVideo[i].data)
			av_free_packet(&pktLastVideo[i]);
	}
    if (pVideoStream)
		avcodec_close(pVideoStream->codec);
    if (pAudioStream)
        avcodec_close(pAudioStream->codec);
	if(pFrameRGB!=NULL)
		av_free(pFrameRGB);
	if(pFrame!=NULL)
		av_free(pFrame);
	if(pVCodecCon!=NULL)
		avcodec_close(pVCodecCon);
	if(pFormatCon!=NULL) {
		if(!bOutput)
			av_close_input_file(pFormatCon);
		else {
			if (!(pFormatCon->oformat->flags & AVFMT_NOFILE)) {
				 /* close the output file */
#ifndef WIN32
				url_fclose(pFormatCon->pb);
#else
				url_fclose(&pFormatCon->pb);
#endif
			}
			av_free(pFormatCon);
		}
	}
}

void CFFMPEGLoader::CheckEvent() {

}

void CFFMPEGLoader::DeleteOlderPTS(const int64_t &pts_t) {
	int64_t pts = pts_t;
	for(UINT j=0; j<iPKTAudioLength; j++) {
		if(pktLastAudio[j].pts<pts||pktLastAudio[j].pts==AV_NOPTS_VALUE||pts_t==AV_NOPTS_VALUE) {
			bLock=true;
			int64_t temp=pktLastAudio[j].pts;
			if(pktLastAudio[j].data)
				av_free_packet(&pktLastAudio[j]);

			iPKTAudioLength--;
			for(UINT i=j; i<iPKTAudioLength;i++)
				pktLastAudio[i]=pktLastAudio[i+1];
			j--;
			pktLastAudio[iPKTAudioLength].data=NULL;
			bLock=false;

			if(temp==AV_NOPTS_VALUE||pts_t==AV_NOPTS_VALUE) break;
		}
	}
}

int CFFMPEGLoader::ReadAudioData(unsigned char *buf, const UINT &buf_size) {
	int len1, data_size;

	for(;iPKTAudioLength>0;) {

		while(audio_pkt_size > 0 && audio_pkt_data) {
			data_size = buf_size;
			bLock=true;
			len1 = avcodec_decode_audio2(pACodecCon, (int16_t *)buf, &data_size, 
										 audio_pkt_data, audio_pkt_size);
			bLock=false;
			if(len1 < 0) {
				/* if error, skip frame */
				audio_pkt_size = 0;
				break;
			}

			audio_pkt_data += len1;
			audio_pkt_size -= len1;

			if(data_size <= 0) {
				/* No data yet, get more frames */
				continue;
			}

			/* We have data, return it and come back for more later */
			return data_size;
		}

		bLock=true;
		if(pktLastAudio[0].data)
			av_free_packet(&pktLastAudio[0]);

		iPKTAudioLength--;
		for(UINT i=0; i<iPKTAudioLength;i++)
			pktLastAudio[i]=pktLastAudio[i+1];
		pktLastAudio[iPKTAudioLength].data=NULL;
		bLock=false;

		if(iPKTAudioLength<1) {
 			return -1;
		}
		audio_pkt_data = pktLastAudio[0].data;
		audio_pkt_size = pktLastAudio[0].size;
	}

	return -1;
}

int CFFMPEGLoader::ReadVideoData(unsigned char **buf, UINT *width, UINT *height) {
	if(iPKTVideoLength<=0) return 0;
	
	int frameFinished;
	int ret = avcodec_decode_video(pVCodecCon, pFrame, &frameFinished,
                         pktLastVideo[0].data, pktLastVideo[0].size);

	*width=*height=0;

	if(ret>0) {
		*width=pVCodecCon->width;
		*height=pVCodecCon->height;
		if(buf)
			*buf=(unsigned char*)pFrame->data[0];
	}

	
	if(pktLastVideo[0].data)
		av_free_packet(&pktLastVideo[0]);
	
	iPKTVideoLength--;
	for(UINT i=0; i<iPKTVideoLength;i++)
		pktLastVideo[i]=pktLastVideo[i+1];
	pktLastVideo[iPKTVideoLength].data=NULL;

	return ret;
}

void CFFMPEGLoader::SaveFrame(int iFrame, const char *add) {
	if(pFrame->linesize[0]==0) return;
  FILE *pFile;
  char szFilename[128];
  int  y;

  
  UINT numBytes=avpicture_get_size(PIX_FMT_RGB24, pVCodecCon->width,
	  pVCodecCon->height)+100;
		uint8_t *buffer2=(uint8_t *)av_malloc(numBytes*sizeof(uint8_t));

  AVCodec* bmpCodec = avcodec_find_encoder(CODEC_ID_BMP);

	AVCodecContext* bmpCodecContext = avcodec_alloc_context();
	avcodec_open(bmpCodecContext, bmpCodec);

	bmpCodecContext->height = pVCodecCon->height;
	bmpCodecContext->width = pVCodecCon->width;


	int encoded = bmpCodec->encode(bmpCodecContext, buffer2, numBytes,
								pFrame); 
	avcodec_close(bmpCodecContext);

  // Open file
  sprintf(szFilename, "fr00000.bmp", add);
  UINT mul=10000,pos=2;
  while(mul>0) {
	  szFilename[pos++]=iFrame/mul+'0';
	  iFrame%=mul;
	  mul/=10;}
  string s=add;
  s+=szFilename;
  pFile=fopen(s.c_str(), "wb");
  if(pFile==NULL)
    return;

  fwrite(buffer2, 1, encoded,pFile); 
  
  // Close file
  fclose(pFile);
  av_free(buffer2);
}

void CFFMPEGLoader::SaveFrame(const char *fn, int wanted_width, int wanted_height) {
	AVFrame *frameIN=NULL,*frameOUT=NULL;
	if(!pFrameRGB->data[1]) {
		frameOUT=pFrameRGB;
		frameIN=pFrame;}
	else {
		frameIN=pFrameRGB;
		frameOUT=pFrame;}
	if(frameIN->linesize[0]==0) return;
  FILE *pFile;
  char szFilename[128];
  int  y;

	if(wanted_width==0) wanted_width=pVCodecCon->width;
	if(wanted_height==0) wanted_height=pVCodecCon->height;

	CodecID id=CODEC_ID_BMP;
	int fmt=PIX_FMT_BGR24;

	{
		string str(fn),ending;
		if(str.find_last_of(".")!=-1)
			ending.append(str,str.find_last_of(".")+1,str.length());

		for(int i=0; i<ending.length(); i++)
			ending[i] = tolower(ending[i]);

		if(ending.compare("jpg")==0||ending.compare("jpeg")==0) {
			id=CODEC_ID_JPEGLS;	//don't work
			fmt=PIX_FMT_RGB32;
		}
		else if(ending.compare("gif")==0) {
			id=CODEC_ID_GIF;	//don't work
			fmt=PIX_FMT_RGB32;
		}
		else if(ending.compare("tiff")==0) {
			id=CODEC_ID_TIFF;
			fmt=PIX_FMT_RGB32;
		}
		else if(ending.compare("png")==0) {
			id=CODEC_ID_PNG;
			fmt=PIX_FMT_RGB32;
		}
	}
  
  UINT numBytes=avpicture_get_size(fmt, wanted_width,
	  wanted_height);
		uint8_t *buffer2=(uint8_t *)av_malloc(numBytes*sizeof(uint8_t));

  AVCodec* bmpCodec = avcodec_find_encoder(id);
  if(!bmpCodec) {
	  av_free(buffer2);
	  return;
  }

	AVCodecContext* bmpCodecContext = avcodec_alloc_context();
	int a=avcodec_open(bmpCodecContext, bmpCodec);
	bmpCodecContext->pix_fmt=(PixelFormat)fmt;

	bmpCodecContext->height = wanted_height;
	bmpCodecContext->width = wanted_width;
	{

		uint8_t *buffer;
		// Determine required buffer size and allocate buffer
		numBytes=avpicture_get_size(fmt, wanted_width,
                            wanted_height)+100;
		pBuffer=buffer=(uint8_t *)av_malloc(numBytes*sizeof(uint8_t));
		avpicture_fill((AVPicture*)frameOUT, buffer, fmt,
                wanted_width, wanted_height);
		
		static struct SwsContext *img_convert_ctx;
		img_convert_ctx = sws_getContext(pVCodecCon->width, pVCodecCon->height, 
									(int)pVCodecCon->pix_fmt, 
										wanted_width, wanted_height, fmt, SWS_BICUBIC, 
										NULL, NULL, NULL);

		if(img_convert_ctx == NULL) {
			cout<<"Cannot initialize the conversion context!\n";
			return;}
    
	a=sws_scale(img_convert_ctx, frameIN->data, 
			      frameIN->linesize, 0, 
				  pVCodecCon->height, 
				  frameOUT->data, frameOUT->linesize);
	sws_freeContext(img_convert_ctx);
	}

	int encoded = bmpCodec->encode(bmpCodecContext, buffer2, numBytes,
								frameOUT); 
	avcodec_close(bmpCodecContext);

  // Open file
  pFile=fopen(fn, "wb");
  if(pFile==NULL)
    return;

  fwrite(buffer2, 1, encoded,pFile); 
  
  // Close file
  fclose(pFile);
  av_free(buffer2);
  av_free(bmpCodecContext);
}

void CFFMPEGLoader::ShowFrameConsole(const unsigned char *buf) {
	if(pFrame->linesize[0]==0) return;
    int  y;
  
	
	// Write pixel data
	for(y=0; y<20; y++) {
		for(UINT x=0; x<50; x++) {
			UINT of=(y*pVCodecCon->height/20*pFrameRGB->linesize[0]+x*pVCodecCon->width/50*3);
			switch(*(buf+of)*5/255) {
				case 4: cout<<(char)255; break;
				case 3: cout<<(char)176; break;
				case 2: cout<<(char)177; break;
				case 1: cout<<(char)178; break;
				default:cout<<(char)219; break;
			}
			//cout<<*(pFrame->data[0]+(y*pVCodecCon->height/20*pFrame->linesize[0]+x*pVCodecCon->width/20*3))%24+'a';
		}
		cout<<endl;
	}
	cout<<endl<<endl;
	// Write pixel data
	for(y=0; y<20; y++) {
		for(UINT x=0; x<50; x++) {
			switch(*(pFrame->data[0]+(y*pVCodecCon->height/20*pFrame->linesize[0]+x*pVCodecCon->width/50*3))*5/255) {
				case 4: cout<<(char)255; break;
				case 3: cout<<(char)176; break;
				case 2: cout<<(char)177; break;
				case 1: cout<<(char)178; break;
				default:cout<<(char)219; break;
			}
			//cout<<*(pFrame->data[0]+(y*pVCodecCon->height/20*pFrame->linesize[0]+x*pVCodecCon->width/20*3))%24+'a';
		}
		cout<<endl;
	}
}


int CFFMPEGLoader::ReadVideoData(unsigned char **buf, UINT *width, UINT *height, int dst_pix_fmt, unsigned char **yuv_buf) {
	//if(!buf||!yuv_buf) return -1;

	if(pBuffer) {
		av_free(pBuffer);
		pBuffer=NULL;}
	//if(pFrame->data) av_free(pFrame);

	if(iPKTVideoLength<=0) return 0;

	struct SwsContext *img_convert_ctx;
	int frameFinished;
	int ret = avcodec_decode_video(pVCodecCon, pFrameRGB, &frameFinished,
                         pktLastVideo[0].data, pktLastVideo[0].size);

	//*width=*height=0;
	if(buf)
		*buf=NULL;
	if(yuv_buf)
		*yuv_buf=NULL;

	double pts=0;
	if(pktLastVideo[0].dts!=AV_NOPTS_VALUE)
		pts=pktLastVideo[0].dts;
	pts*=av_q2d(pVCodecCon->time_base);

	if(ret>0&&pFrameRGB->linesize[0]+pFrameRGB->linesize[1]+pFrameRGB->linesize[2]+pFrameRGB->linesize[3]>0) {

		UINT wanted_width=*width, wanted_height=*height;

		*width=pVCodecCon->width;
		*height=pVCodecCon->height;

		if(wanted_width==0) wanted_width=*width;
		if(wanted_height==0) wanted_height=*height;

		uint8_t *buffer;
		UINT numBytes;
		// Determine required buffer size and allocate buffer
		numBytes=avpicture_get_size(dst_pix_fmt, wanted_width,
                            wanted_height)+100;
		pBuffer=buffer=(uint8_t *)av_malloc(numBytes*sizeof(uint8_t));
		avpicture_fill((AVPicture*)pFrame, buffer, dst_pix_fmt,
                wanted_width, wanted_height);
		
		img_convert_ctx = sws_getContext(*width, *height, 
									(int)pVCodecCon->pix_fmt, 
										wanted_width, wanted_height, dst_pix_fmt, SWS_BICUBIC, 
										NULL, NULL, NULL);

		if(img_convert_ctx == NULL) {
			cout<<"Cannot initialize the conversion context!\n";
			return -1;}
    
		sws_scale(img_convert_ctx, pFrameRGB->data, 
			      pFrameRGB->linesize, 0, 
				  *height, 
				  pFrame->data, pFrame->linesize);
		sws_freeContext(img_convert_ctx);

		if(buf)
			*buf=(unsigned char*)pFrame->data[0];
		if(yuv_buf)
			*yuv_buf=(unsigned char*)pFrameRGB->data[0];
		
		*width=wanted_width;
		*height=wanted_height;
	}

	
	if(pktLastVideo[0].data)
		av_free_packet(&pktLastVideo[0]);
	
	iPKTVideoLength--;
	for(UINT i=0; i<iPKTVideoLength;i++)
		pktLastVideo[i]=pktLastVideo[i+1];
	pktLastVideo[iPKTVideoLength].data=NULL;

	return ret;
}

void CFFMPEGLoader::Seek(const UINT &iSec, const uint64_t &iFrame, const bool &bExact, const int &dst_pix_fmt ) {
	int64_t seek_target=0;

	
	for(UINT i=0; i<iPKTVideoLength; i++) {
		if(pktLastVideo[i].data) {
			av_free_packet(&pktLastVideo[i]);
			pktLastVideo[i].data=NULL;}
	}
	iPKTVideoLength = 0;

	bLock=true;
	for(UINT i=0; i<iPKTAudioLength; i++) {
		if(pktLastAudio[i].data) {
			av_free_packet(&pktLastAudio[i]);
			pktLastAudio[i].data=NULL;}
	}
	iPKTAudioLength = 0;
	bLock=false;

	AVRational temp;
	temp.num=1;
	temp.den=AV_TIME_BASE;

	/*	seek_target = av_rescale_q(iFrame+iSec*pFormatCon->streams[videoStream]->time_base.den, temp,
                      pFormatCon->streams[videoStream]->time_base);

    av_seek_frame( pFormatCon, -1, seek_target, AVSEEK_FLAG_BACKWARD );
    pVCodecCon->hurry_up = 1;
	int gotFrame;
	AVPacket Packet;
	uint64_t MyPts=0;
    do {
        av_read_frame( pFormatCon, &Packet );
        // should really be checking that this is a video packet
        MyPts=av_rescale( Packet.pts,
            AV_TIME_BASE * (int64_t) pFormatCon->streams[videoStream]->time_base.num,
            pFormatCon->streams[videoStream]->time_base.den );
        // Once we pass the target point, break from the loop
        if( MyPts >= seek_target )
            break;
        avcodec_decode_video( pVCodecCon, pFrame, &gotFrame, Packet.data,
            Packet.size );
        av_free_packet( &Packet );
    } while(1);
    pVCodecCon->hurry_up = 0;*/
	if(pVCodecCon) {
		int64_t si_st = iFrame+iSec*GetFPS();//)*pVCodecCon->time_base.den; //av_rescale_q( (iFrame+iSec*pFormatCon->streams[videoStream]->time_base.den), temp,
                      //pFormatCon->streams[videoStream]->time_base);
		//seek_target=av_rescale( iFrame+iSec*pVCodecCon->time_base.den,
        //    AV_TIME_BASE * (int64_t) pFormatCon->streams[videoStream]->time_base.num,
        //    pFormatCon->streams[videoStream]->time_base.den );
		seek_target= si_st;//av_rescale_q(iSec*AV_TIME_BASE+iFrame*AV_TIME_BASE/GetFPS(), temp,
                      //pFormatCon->streams[videoStream]->time_base);

	int gotFrame;
	bool bIFrame=false;
	//AVPacket Packet;
	//uint64_t MyPts=0;
    //av_read_frame( pFormatCon, &Packet );
    //MyPts=av_rescale_q( Packet.pts, temp,
    //        pFormatCon->streams[videoStream]->time_base );
	//MyPts=av_rescale( Packet.dts,
  //          AV_TIME_BASE * (int64_t) pFormatCon->streams[videoStream]->time_base.num,
//            pFormatCon->streams[videoStream]->time_base.den );

	//if(Packet.dts > si_st|| (MyPts<seek_target-20*pFormatCon->streams[videoStream]->time_base.den&&seek_target>=20*pFormatCon->streams[videoStream]->time_base.den) ) {
		if(av_seek_frame(pFormatCon, videoStream, 
			seek_target, AVSEEK_FLAG_BACKWARD) < 0)
			cout<<"error while seeking\n";
		
	//}
    //pVCodecCon->hurry_up = 1;
    do {

		UINT w=0,h=0;
		if(dst_pix_fmt==-1) {
		while( ReadVideoData(NULL,&w,&h)==0 )
			if(LoadFrame()<0) return;
		}
		else {
			unsigned char *buf;
			while( ReadVideoData(&buf,&w,&h,dst_pix_fmt,&buf)==0 )
			if(LoadFrame()<0) return;
		}
        
		/*if(iPKTAudioLength>0){
			if(pktLastAudio[0].data)
				av_free_packet(&pktLastAudio[0]);

			iPKTAudioLength--;
			for(UINT i=0; i<iPKTAudioLength;i++)
				pktLastAudio[i]=pktLastAudio[i+1];
			pktLastAudio[iPKTAudioLength].data=NULL;
		}*/
		static unsigned char buffer[4096];
		ReadAudioData(buffer,4096);

		if( pktLastVideo[0].dts >= seek_target ) {
			if(!bIFrame&&bExact&&iSec!=0){
				Seek(iSec-2,iFrame,false,dst_pix_fmt);
				bIFrame=true;
//				cout<<"SHIT";
				//if(iSec!=0)
					;//Seek(iSec>1?iSec-1:0);
			}
			else
				break;}
        //avcodec_decode_video( pVCodecCon, pFrame, &gotFrame, Packet.data,
         //   Packet.size );
		int pt=0;
		if(dst_pix_fmt==-1)
			pt=pFrame->pict_type;
		else
			pt=pFrameRGB->pict_type;
		if(pt==FF_I_TYPE) {
			if(!bExact) break;
			bIFrame=true;
		}
		

    } while(1);
    //pVCodecCon->hurry_up = 0;
	//if(av_seek_frame(pFormatCon, audioStream, 
    //                seek_target, 0) < 0)
	//		cout<<"error while seeking\n";
	}
	/*if(pACodecCon) {
		seek_target = av_rescale_q(iFrame+iSec*pFormatCon->streams[audioStream]->time_base.den, temp,
			pFormatCon->streams[audioStream]->time_base);
		if(av_seek_frame(pFormatCon, audioStream, 
                    seek_target, 0) < 0)
			cout<<"error while seeking\n";
	}*/
}

bool CFFMPEGLoader::CreateMovie(const char *filename, const AVOutputFormat *format, const AVCodecContext *VideoCon, const AVCodecContext *AudioCon) {
	if(!filename) 
		return false;
	
    AVOutputFormat *fmt;
	//*fmt=*format;
    fmt = guess_format(NULL, filename, NULL);

	pFormatCon = av_alloc_format_context();
	if(!pFormatCon) {
		cout<<"Error while allocating format context\n";
		return false;}
	bOutput=true;
	strcpy(pFormatCon->filename,filename);

	pFormatCon->oformat=fmt;
	pAudioStream=pVideoStream=NULL;

    if (fmt->video_codec != CODEC_ID_NONE) {
        pVideoStream = add_video_stream(pFormatCon, fmt->video_codec,VideoCon);
    }
    if (fmt->audio_codec != CODEC_ID_NONE) {
        pAudioStream = add_audio_stream(pFormatCon, fmt->audio_codec,AudioCon);
    }
	
    if (av_set_parameters(pFormatCon, NULL) < 0) {
        cout<<"Invalid output format parameters\n";
        return false;
    }
	
    if (pVideoStream)
        open_stream(pFormatCon, pVideoStream);
    if (pAudioStream)
        open_stream(pFormatCon, pAudioStream);

    dump_format(pFormatCon, 0, filename, 1);

	if (!(fmt->flags & AVFMT_NOFILE)) {
        if (url_fopen(&pFormatCon->pb, filename, URL_WRONLY) < 0) {
            cout<<"Could not open '%s'"<<filename<<endl;
            return false;
        }
    }

    /* write the stream header, if any */
    av_write_header(pFormatCon);
	return true;
}

void CFFMPEGLoader::CloseWriting() {
    /* write the trailer, if any */
    av_write_trailer(pFormatCon);
}

void CFFMPEGLoader::PopVideoPacket() {
	if(pktLastVideo[0].data)
		av_free_packet(&pktLastVideo[0]);
	
	iPKTVideoLength--;
	for(UINT i=0; i<iPKTVideoLength;i++)
		pktLastVideo[i]=pktLastVideo[i+1];
	pktLastVideo[iPKTVideoLength].data=NULL;
}

void CFFMPEGLoader::PopAudioPacket() {
	bLock=true;
	if(pktLastAudio[0].data)
		av_free_packet(&pktLastAudio[0]);
	
	iPKTAudioLength--;
	for(UINT i=0; i<iPKTAudioLength;i++)
		pktLastAudio[i]=pktLastAudio[i+1];
	pktLastAudio[iPKTAudioLength].data=NULL;
	bLock=false;
}

void CFFMPEGLoader::DeleteBuffer() {
	while(GetNextVideoPacket()) PopVideoPacket();
	while(GetNextAudioPacket()) PopAudioPacket();
}

void CFFMPEGLoader::CopyPacktes(CFFMPEGLoader *FFMPEG, const uint64_t &firstFrame, const uint64_t &lastFrame) {
	AVPacket *last=NULL;

	bool b1=true,b2=true;

	FFMPEG->ClearAudio();
	FFMPEG->Seek(firstFrame/25,0);
	//FFMPEG->DeleteBuffer();

	uint64_t big=0,big2=0,dif=0,dif2=0;

	int64_t temp=0;

	while(true) {
			
		if(FFMPEG->LoadFrame()<0) {
			if(big>i64DTS)
				i64DTS=big;
			if(big2>i64PTS)
				i64PTS=big2;
			return;
		}
			
			while( (last=FFMPEG->GetNextVideoPacket())!=NULL&&last->dts<lastFrame) {
				if(dif==0&&last->dts!=0) {
					dif = last->dts-i64DTS;
					dif2= last->pts-i64PTS;
				}
				last->dts-=dif;
				if(last->dts<0) 
					last->dts+=dif;
				if(last->dts>big) 
					big=last->dts;
				last->pts-=dif2;	//http://thefoundry.anywebcam.com/index.php/image-processing/transcoding-with-libavformatlibavcodec/
				if(last->pts<0) 
					last->pts+=dif2;
				if(last->pts>big2) 
					big2=last->pts;
				last->pts=last->dts=temp;
				av_write_frame(pFormatCon,last);
				temp++;
				FFMPEG->PopVideoPacket();
				b1=false;
			}
			if(last&&last->dts>=lastFrame) b1=true;
			
			while( (last=FFMPEG->GetNextAudioPacket())!=NULL&&last->dts<lastFrame) {
				last->dts+=i64PTS;
				last->pts+=i64PTS;
				av_write_frame(pFormatCon,last);
				FFMPEG->PopAudioPacket();
				b2=false;
			}
			if(last&&last->dts>=lastFrame) b2=true;

			if(b1&&b2) {
				if(big>i64DTS)
					i64DTS=big;
				if(big2>i64PTS)
					i64PTS=big2;
				return;
			}

		/*while( (last=FFMPEG->GetNextPacket())!=NULL ) {
				if(dif==0) {
					dif = last->dts-i64DTS;
				}
				last->dts-=dif;
				if(last->dts>big) big=last->dts;
				last->pts=i64PTS++;
				av_write_frame(pFormatCon,last);
				av_free_packet(last);
				
				if(last->dts>lastFrame) {
					b1=false;
					break;}
			}*/

	}

	if(big>i64DTS)
		i64DTS=big;
	if(big2>i64PTS)
		i64PTS=big2;
}

void CFFMPEGLoader::WriteFrame(const AVFrame *frame) {
/*	int out_size = avcodec_encode_video(pVideoStream->codec, video_outbuf, video_outbuf_size, (AVPichture*)frame);
	/* if zero size, it means the image was buffered *//*
	if (out_size > 0) {
		AVPacket pkt;
		av_init_packet(&pkt);

		pkt.pts= av_rescale_q(pVideoStream->codec->coded_frame->pts, pVideoStream->codec->time_base, pVideoStream->time_base);
		if(pVideoStream->codec->coded_frame->key_frame)
			pkt.flags |= PKT_FLAG_KEY;
		pkt.stream_index= st->index;
		pkt.data= video_outbuf;
		pkt.size= out_size;

		/* write the compressed frame in the media file *//*
		av_write_frame(pFormatCon, &pkt);
        }*/
}


void CFFMPEGLoader::open_stream(AVFormatContext *oc, AVStream *st)
{
    AVCodec *codec;
    AVCodecContext *c;

    c = st->codec;

    /* find the video encoder */
    codec = avcodec_find_encoder(c->codec_id);
    if (!codec) {
        cout<<"codec not found\n";
        return;
    }

    /* open the codec */
    if (avcodec_open(c, codec) < 0) {
        cout<<"could not open codec\n";
        return;
    }

    /*video_outbuf = NULL;
    if (!(oc->oformat->flags & AVFMT_RAWPICTURE)) {
        /* allocate output buffer *
        /* XXX: API change will be done */
        /* buffers passed into lav* can be allocated any way you prefer,
           as long as they're aligned enough for the architecture, and
           they're freed appropriately (such as using av_free for buffers
           allocated with av_malloc) *
        video_outbuf_size = 200000;
        video_outbuf = av_malloc(video_outbuf_size);
    }

    /* allocate the encoded raw picture *
    picture = alloc_picture(c->pix_fmt, c->width, c->height);
    if (!picture) {
        fprintf(stderr, "Could not allocate picture\n");
        exit(1);
    }

    /* if the output format is not YUV420P, then a temporary YUV420P
       picture is needed too. It is then converted to the required
       output format *
    tmp_picture = NULL;
    if (c->pix_fmt != PIX_FMT_YUV420P) {
        tmp_picture = alloc_picture(PIX_FMT_YUV420P, c->width, c->height);
        if (!tmp_picture) {
            fprintf(stderr, "Could not allocate temporary picture\n");
            exit(1);
        }
    }*/
}

AVStream *CFFMPEGLoader::add_video_stream(AVFormatContext *oc, int codec_id, const AVCodecContext *Con)
{
    AVCodecContext *c;
    AVStream *st;

    st = av_new_stream(oc, 0);
    if (!st) {
        cout<<"Could not alloc stream\n";
        return NULL;
    }

    c = st->codec;
	c->codec_id = Con->codec_id;
	c->codec_type = Con->codec_type;

    /* put sample parameters */
	c->bit_rate = Con->bit_rate;
    /* resolution must be a multiple of two */
	c->width = Con->width;
	c->height = Con->height;
    /* time base: this is the fundamental unit of time (in seconds) in terms
       of which frame timestamps are represented. for fixed-fps content,
       timebase should be 1/framerate and timestamp increments should be
       identically 1. */
	c->time_base = Con->time_base;
	c->gop_size = Con->gop_size; /* emit one intra frame every twelve frames at most */
	c->pix_fmt = Con->pix_fmt;
	c->max_b_frames= Con->max_b_frames;
	c->mb_decision= Con->mb_decision;
	c->flags=Con->flags;

	//*c=*Con;
    return st;
}

AVStream *CFFMPEGLoader::add_audio_stream(AVFormatContext *oc, int codec_id, const AVCodecContext *Con)
{
    AVCodecContext *c;
    AVStream *st;

    st = av_new_stream(oc, 1);
    if (!st) {
        cout<<"Could not alloc stream\n";
        return NULL;
    }

    c = st->codec;
	c->codec_id = Con->codec_id;
	c->codec_type = Con->codec_type;

    /* put sample parameters */
	c->bit_rate = Con->bit_rate;
	c->sample_rate = Con->sample_rate;
	c->channels = Con->channels;

	//*c=*Con;
    return st;
}
